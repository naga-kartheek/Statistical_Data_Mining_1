---
title: "Homework 1"
author: "Naga Kartheek Peddisetty, 50538422"
date: "9/11/2023"
output:
  html_document: default
  pdf_document: default
---

## Question 1
#### Consider	the	“Smarket” data	in	the	ISLR2	package data(Smarket)
#### a)	What	is	the	dimension	of	this	data?
```{r}
library(ISLR2)
data(Smarket)
dim(Smarket)

## OR

nrow(Smarket)
ncol(Smarket)
```
##### 1250(rows) Observations of 9(columns) variables.
#### b) What are the average for: Lag1 – Lag5.	Calculate this in two different ways.
```{r}
#### Type - 1
colMeans(Smarket[,2:6])
```
##### OR
```{r}
#### Type - 2
apply(Smarket[,2:6],2,mean)
```
#### c)	What	type	of	variable	is	Direction.Using	the	table	function,	comment	on the	frequency	of	Up	and	Down.
```{r}
class(Smarket$Direction)
typeof(Smarket$Direction)
```
```{r}
table(Smarket$Direction)
```
##### Frequency of Down is 602 and Frequency of Up is 648.
#### d)	Create	a	list	object	with	data.frames	for	2001,	2002,	2003,	2004 and 2005.  
```{r}
Year_2001 <- Smarket[Smarket$Year =="2001", ]
Year_2002 <- Smarket[Smarket$Year =="2002", ]
Year_2003 <- Smarket[Smarket$Year =="2003", ]
Year_2004 <- Smarket[Smarket$Year =="2004", ]
Year_2005 <- Smarket[Smarket$Year =="2005", ]

Yearly_data <- list(Year_2001,Year_2002,Year_2003,Year_2004,Year_2005)
# Yearly_data[1] for 2001.
```
##### As shown above i created a list object with yearly data frames. We can access them by using Yearly_data[1] for 2001, Yearly_data[2] for 2002, ....,Yearly_data[5] for 2005.

## Question 2
#### Consider the “Hitters” dataset in the ISLR2 package. Suppose that you are  getting this data ready to build a predictive model for salary.Pre-process/clean the data, investigate the data using exploratory data analysis such as scatterplots, and other tools we have discussed. Describe your process and justify any changes you have made to the dataset. Submit the cleaned dataset as an *.RData file to BrightSpace. 

```{r}
library(ISLR2)
data(Hitters)
```
```{r}
str(Hitters)
```
```{r}
head(Hitters)
summary(Hitters$Salary)
```
##### Salary contains 59 Null(NA) values.
```{r}
dim(Hitters)
```
##### 322(rows) Observations of 20(columns) variables.

```{r}
## Finding mean of the salary column by excluding null values.

mean(Hitters$Salary, na.rm = TRUE)

Hitters_dats <- Hitters

## Imputing Salary with mean.
## replacing null values in Salary column with it's mean.

Hitters_dats$Salary <- replace(Hitters_dats$Salary,is.na(Hitters_dats$Salary),535.9259) 
summary(Hitters_dats$Salary)  
```
###### No null(NA) values in Salary column.

```{r}
head(Hitters_dats$Salary)
```

#### Exploratory Data analysis

```{r}
plot(Hitters_dats$Years,Hitters_dats$Salary, xlab = "Years", ylab = "Salary", main = "Years vs Salary")
```

##### Number of years in the major leagues is more, then salary will increase upto 15 years after it's decreasing.
```{r}
pairs(Hitters_dats, las = 2, main = "Hitters_dats")
hist(Hitters_dats$Salary, breaks = 25, main = "Histogram of Salary", xlab="salary")
```

##### Frequency of Salary is peak at 535.92 because we impute the mean of the salary.

```{r}
hist(Hitters_dats$Hits, xlab = "Hits", main = "Histogram of Hits")
```

##### Lattice plot
```{r}
## Plot of two continuous variables runs and years vs categorical variable division.

library(lattice)
xyplot(Runs~Years | Division, data = Hitters_dats)
```

#### Box plot
```{r}
boxplot(Hitters_dats$Salary,main = "Box plot of Salary" )
summary(Hitters_dats$Salary)
```

### Eliminating Outliers :
##### IQR(Inter quartile range) = Q3 - Q1 = 700 - 226.2 = 473.8
##### Outliers are greater than Q3 + (1.5 * IQR) or less than Q1 - (1.5 * IQR)
##### Q3 + (1.5 * IQR) = 700 + (1.5 * 473.8) = 1410.7

```{r}
##indexes of data where Salary values are greater than 1410.7, storing in elim.

elim <- which(Hitters_dats$Salary > 1410.7) 
elim

## data of salary greater than 1410.7

Hitters_dats[Hitters_dats$Salary > 1410.7, ]   

dim(Hitters_dats)
## Eliminating (outliers from box plot) 13 rows from Hitters_Dats and saving in Hitters_dats_elim.

Hitters_dats_elim <- Hitters_dats[-elim, ]   
dim(Hitters_dats_elim)

boxplot(Hitters_dats_elim$Salary, main = "Box plot of Salary after elimination of outliers" )

## saving the modified or cleaned dataset as RData file.

save(Hitters_dats_elim, file = "Naga_Kartheek_Peddisetty_50538422_HW1.RData") 
```

## Question 3
#### Divide your data from Q2 into training and test. Use k-nearest neighbors to predict salary. Justify your choice of “k”. Provide a profile of the test and training error as a function of the number of neighbors “k”.
```{r}
# dividing the data from Question 2 into training and test.

## taking the length of row in data set. Defining total number of data points.

N = length(Hitters_dats_elim[,1])
N

Hitters_dats_elim1 <- Hitters_dats_elim

#### Converting league, New league & division into numeric values.

Hitters_dats_elim1$League <- as.numeric(Hitters_dats_elim1$League)

Hitters_dats_elim1$NewLeague <- as.numeric(Hitters_dats_elim1$NewLeague)

Hitters_dats_elim1$Division <- as.numeric(Hitters_dats_elim1$Division)

set.seed(219)

#### Generating a 2/3 of sample data for training with out replacing.

train_Hitters_dats_elim <- sample(1:N, size = (2/3)*N, replace = FALSE)

#### Dividing data into training and testing, 

training_data <- Hitters_dats_elim1[train_Hitters_dats_elim, ]  
testing_data <- Hitters_dats_elim1[-train_Hitters_dats_elim, ]
dim(training_data)
dim(testing_data)

### training data except Salary column

X_train = training_data[, -19]  

### training data of salary column

Y_train = training_data[, 19]   

### testing data except Salary column

X_test =  testing_data[, -19]  

### training data of salary column

Y_test = testing_data[, 19]     
################################################

library(class)

### Taking k values from 1 to 20.

k_values <- 1:20
train_err <- numeric(length(k_values))
test_err  <- numeric(length(k_values))

##### using for loop to calculate knn, train and test error values. 

for (k in k_values) {
  
  knn_model <- knn(X_train,X_test,Y_train,k=k)
  train_err[k] <- mean(knn_model != Y_train)
  test_err[k] <- mean(knn_model != Y_test)
  
}

# Plotting of training and test errors as a function of k

plot(k_values, train_err, type = "o", col = "orange", pch = 19, xlab = "k", ylab = "Error Rate", main = "Training and Test Error vs. k")
points(k_values, test_err, type = "o", col = "blue", pch = 19)
legend("topright", legend = c("Training Error", "Test Error"), col = c("orange", "blue"), pch = 19)

#### We can choose the best value for k at which the minimum test error occurs.
best_value_k <- k_values[which.min(test_err)]
best_value_k
```
##### The best value for k = 8. Because, the test error is minimum at k=8 as shown in the above plot.

## Question 4
#### To begin,load in the Boston data set. The Boston data set is part of the ISLR2 library.
#### a) How many rows are in this data set? How many columns? What do the rows and columns represent.
```{r}
library(ISLR2)
data(Boston)
?Boston
dim(Boston)

## OR

nrow(Boston)
ncol(Boston)
```
##### 506(rows) observations of 13(columns) variables. And data(rows and columns) represents the housing values in 506 suburbs of Boston.

#### b)Make some pairwise scatterplots of the predictors (columns) in this data set. Describe your findings.    
```{r}
str(Boston)
Boston_dats <- Boston

## Converting integer to numeric for chas and rad.

Boston_dats$chas <- as.numeric(Boston_dats$chas)  
Boston_dats$rad <- as.numeric(Boston_dats$rad)   
pairs(Boston_dats, las = 2, main = "Housing values in 506 suburbs of Boston")
```

##### -> 'crim' is positively correlated with indus,nox,age,rad,tax and lstat. Negatively correlated with dis and medv.

##### -> 'zn' is positively correlated with dis and medv. Negatively correlated with indus,nox,age,ptratio and lstat.

##### -> 'indus' is positively correlated with nox,age,rad,tax,lstat and ptratio. Negatively correlated with dis,medv and rm.

##### -> 'nox' is positively correlated with age,rad,tax and lstat. Negatively correlated with dis and medv.

##### -> 'rm' is positively correlated with medv. Negatively correlated with lstat and ptratio.

##### -> 'age' is positively correlated with lstat,tax and rad. Negatively correlated with dis and medv.

##### -> 'dis' is negatively correlated with tax,rad and lstat.

##### -> 'rad' is positively correlated with tax,lstat and ptratio. Negatively correlated with medv.

##### -> 'tax' is positively correlated with lstat and ptratio. Negatively correlated with medv.

##### -> 'ptratio' is positively correlated with lstat. Negatively correlated with medv.

##### -> 'lstat' is negatively correlated with medv.

#### c) Are any of the predictors associated with per capita crime rate?If so, explain the relationship.

##### As mentioned above in question b 'crim' is positively correlated with indus,nox,age,rad,tax and lstat. Negatively correlated with dis and medv.
```{r}
## For better understanding of the plot i am using transformations.

## Transforming indus and crim values into logarithm.

log_indus <- log(Boston$indus)   
log_crim  <- log(Boston$crim)    
plot(log_indus,log_crim,xlab = 'log(indus)',ylab = 'log(crim)',main = "log(indus) vs log(crim)")
```

##### As shown in the above plot crim is positively correlated with indus. Because if crime rate is increasing, indus is also increasing.

```{r}
## Transforming nox values into logarithm.

log_nox <- log(Boston$nox)   
plot(log_nox,log_crim,xlab = 'log(nox)',ylab = 'log(crim)',main = "log(nox) vs log(crim)")
```

##### As shown in the above plot crim is positively correlated with nox. Because if crime rate is increasing, nox is also increasing.

```{r}
## Transforming age values into logarithm.

log_age <- log(Boston$age)   
plot(log_age,log_crim,xlab = 'log(age)',ylab = 'log(crim)',main = "log(age) vs log(crim)")
```

##### As shown in the above plot crim is positively correlated with age. Because if crime rate is increasing, age is also increasing.

```{r}
## Transforming rad values into logarithm.

log_rad <- log(Boston$rad)   
plot(log_rad,log_crim,xlab = 'log(rad)',ylab = 'log(crim)',main = "log(rad) vs log(crim)")
```

##### As shown in the above plot crim is positively correlated with rad. Because if crime rate is increasing, rad is also increasing.

```{r}
## Transforming tax values into logarithm.

log_tax <- log(Boston$tax)   
plot(log_tax,log_crim,xlab = 'log(tax)',ylab = 'log(crim)',main = "log(tax) vs log(crim)")
```

##### As shown in the above plot crim is positively correlated with tax. Because if crime rate is increasing, tax is also increasing.

```{r}
## Transforming lstat values into logarithm.

log_lstat <- log(Boston$lstat)   
plot(log_lstat,log_crim,xlab = 'log(lstat)',ylab = 'log(crim)',main = "log(lstat) vs log(crim)")
```

##### As shown in the above plot crim is positively correlated with lstat. Because if crime rate is increasing, lstat is also increasing.

```{r}
## Transforming dis values into logarithm.

log_dis <- log(Boston$dis)   
plot(log_dis,log_crim,xlab = 'log(dis)',ylab = 'log(crim)',main = "log(dis) vs log(crim)")
```

##### As shown in the above plot crim is negatively correlated with dis. Because if crime rate is increasing, dis is decreasing.

```{r}
## Transforming medv values into logarithm.

log_medv <- log(Boston$medv)   
plot(log_medv,log_crim,xlab = 'log(medv)',ylab = 'log(crim)',main = "log(medv) vs log(crim)")
```

##### As shown in the above plot crim is negatively correlated with medv. Because if crime rate is increasing, medv is decreasing.

#### d) Do any of the census tracts of Boston appear to have particularly high crime rates? Tax rates? Pupil-teacher ratios? Comment on the range of each predictor.

```{r}
hist(Boston$crim[Boston$crim>1], breaks=25, xlab = "crim", main = "Histogram of crim" )
sum(Boston$crim>20)
```

##### most suburbs have low crime rates, but there is 18 suburbs appear to have a crime rate greater than 20 reaching to above 80.

```{r}
hist(Boston$tax, breaks=25,xlab = "tax", main = "Histogram of tax")
sum(Boston$tax > 660 & Boston$tax < 680)
```

##### There is a large gap between suburbs with low tax rates and high tax rates, we can see a peak at 660 to 680(132 suburbs are in between 660 to 680).

```{r}
hist(Boston$ptratio, breaks=25,xlab = "ptratio", main = "Histogram of ptratio")
sum(Boston$ptratio > 20)
```

##### There is a peak towards high ratios and particularly greater than 20(201 suburbs have ptratio greater than 20).

#### e) How many of the census tracts in this data set bound the Charles river?

```{r}
sum(Boston$chas == 1)

## OR

nrow(subset(Boston, chas == 1))
```
##### 35 census tracts in this data set bound the Charles river.

#### f) What is the median pupil-teacher ratio among the towns in this data set?
```{r}
median(Boston$ptratio)
```
##### 19.05 is the median pupil-teacher ratio among the towns in this data set. Means 19 pupils for each teacher.

#### g) Which census tract of Boston has lowest median value of owner occupied homes? What are the values of the other predictors for that census tract, and how do those values compare to the overall ranges for those predictors? Comment on your findings.

```{r}
summary(Boston)
```
```{r}
t(subset(Boston[Boston$medv == min(Boston$medv), ]))

## OR

t(subset(Boston,medv == min(Boston$medv)))
```
##### Below are the comparision of predictors(columns) with overall range,
##### "crim" is above the 3rd quartile
##### "zn" is at minimum
##### "indus" is at 3rd quartile
##### "chas" not bounded by river
##### "nox" is above 3rd quartile
##### "rm" is below 1st quartile
##### "age" is at maximum
##### "dis" is below 1st quartile
##### "rad" is at maximum
##### "tax" is at 3rd quartile
##### "ptratio" is at 3rd quartile
##### "lstat" is above 3rd quartile
##### "medv" is at minimum

##### Because of the crime rate is above the 3rd quartile it is not the best place to live, but certainly not the worst.


#### h) In this data set, how many of the census tracts average more than seven rooms per dwelling? More than eight rooms per dwelling? Comment on the census tracts that average more than eight rooms per dwelling.

```{r}
sum(Boston$rm > 7)
```
##### There are 64 census tracts that average more than seven rooms per dwelling.
```{r}
sum(Boston$rm > 8)
```
##### There are 13 census tracts that average more than eight rooms per dwelling.
```{r}
summary(Boston)
summary(subset(Boston[Boston$rm >8, ]))
```
##### While comparing with the overall range it has relatively lower "crime rate(crim)" and lower "lower status of the population percent(lstat)".

